{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "precomputed_filename = 'precomputed_clips'\n",
    "\n",
    "def load_precomputed(precomputed_filename):\n",
    "    with open(precomputed_filename + '.pickle', 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "precomputed_dict = load_precomputed(precomputed_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def get_clip_embeddings(input_data, input_type='text'):\n",
    "    # Load the CLIP model and processor\n",
    "    model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "    processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "\n",
    "    # Prepare the input based on the type\n",
    "    if input_type == 'text':\n",
    "        inputs = processor(text=input_data, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    elif input_type == 'image':\n",
    "        if isinstance(input_data, str):\n",
    "            image = Image.open(input_data)\n",
    "        elif isinstance(input_data, Image.Image):\n",
    "            image = input_data\n",
    "        else:\n",
    "            raise ValueError(\"For image input, provide either a file path or a PIL Image object\")\n",
    "        inputs = processor(images=image, return_tensors=\"pt\")\n",
    "    else:\n",
    "        raise ValueError(\"Invalid input_type. Choose 'text' or 'image'\")\n",
    "\n",
    "    # Get the embeddings\n",
    "    with torch.no_grad():\n",
    "        if input_type == 'text':\n",
    "            embeddings = model.get_text_features(**inputs)\n",
    "        else:\n",
    "            embeddings = model.get_image_features(**inputs)\n",
    "\n",
    "    return embeddings.numpy()\n",
    "\n",
    "\n",
    "def find_similar_images(text_input, image_embeddings, all_images, take_best = 4):\n",
    "    # Získání embeddingu pro text\n",
    "    text_embedding = get_clip_embeddings(text_input, input_type='text')\n",
    "\n",
    "    # Výpočet kosinové podobnosti mezi textem a obrázky\n",
    "    similarities = cosine_similarity(text_embedding, image_embeddings)\n",
    "\n",
    "    # Seřazení podle podobnosti\n",
    "    best_indices = np.argsort(similarities[0])[::-1][:take_best]\n",
    "\n",
    "    # Výběr nejlepších 4 obrázků\n",
    "    best_images = [all_images[i] for i in best_indices]\n",
    "    return [Image.open(img) for img in best_images]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_most_similar(text_input):\n",
    "    return find_similar_images(text_input, precomputed_dict['image_clips'], precomputed_dict['image_paths'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/gradio/analytics.py:106: UserWarning: IMPORTANT: You are using gradio version 4.44.1, however version 5.0.1 is available, please upgrade. \n",
      "--------\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on public URL: https://dbeaf92d1b9d6bc345.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://dbeaf92d1b9d6bc345.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr  # Importing Gradio for creating the web interface\n",
    "\n",
    "# vytvoření Gradio rozhraní\n",
    "interface = gr.Interface(\n",
    "    fn=find_most_similar,\n",
    "    inputs=\"text\",\n",
    "    outputs=gr.Gallery(label=\"Most Similar Images\"),\n",
    "    title=\"Find Similar Images with CLIP\",\n",
    "    description=\"Enter a text prompt to find the most similar images.\"\n",
    ")\n",
    "\n",
    "# spuštění aplikace\n",
    "interface.launch() "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
